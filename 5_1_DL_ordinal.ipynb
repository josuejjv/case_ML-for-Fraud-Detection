{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "5_1_DL_ordinal.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOxWyvY/UaKamA8zm414x6T",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ryanhao1115/ML-for-Fraud-Detection/blob/main/5_1_DL_ordinal.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ndtW0FwNmcWr",
        "outputId": "12f55f55-2aab-4c1f-8793-911b70f2924d"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oINI7xYSmpo8"
      },
      "source": [
        "## Deep Learning model with Ordinal encoding data\n",
        "1. import new return label data.\n",
        "2. Under sampling data to address imbalance class issue.\n",
        "4. Train model\n",
        "5. Eval model\n",
        "6. Create Risk-heatmap"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Gc_G68myO1w"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.backend import clear_session\n",
        "from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix\n",
        "import tensorflow as tf\n",
        "import random\n"
      ],
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wr3fxm5Waw2H"
      },
      "source": [
        "def reset_seeds():\n",
        "    '''\n",
        "    reset random seeds for modeling\n",
        "    '''\n",
        "    np.random.seed(1)\n",
        "    random.seed(2)\n",
        "    if tf.__version__[0] == '2':\n",
        "        tf.random.set_seed(3)\n",
        "    else:\n",
        "        tf.set_random_seed(3)\n",
        "    print(\"RANDOM SEEDS RESET\")"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EB5yPnJdyRnG"
      },
      "source": [
        "## import dataset \n",
        "path = '/content/drive/MyDrive/Colab Notebooks/finalproject/'\n",
        "file = path + 'sales_clean.csv'\n",
        "df = pd.read_csv(file)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zM0xX0nKWIu0"
      },
      "source": [
        "df = df.drop(columns='Unnamed: 0')"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tXuAbPlSyWVW",
        "outputId": "e12cbefe-322b-41c4-f4cd-0661483ad5f7"
      },
      "source": [
        "df.nunique()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "distributor        639\n",
              "sales              209\n",
              "branch              28\n",
              "inv_type             3\n",
              "invoice_no       30721\n",
              "product_no        1094\n",
              "prod_cla             7\n",
              "qty                202\n",
              "total_amt        16112\n",
              "sale_price        8598\n",
              "ship_qty           202\n",
              "cust_type           20\n",
              "return               2\n",
              "discount_app         2\n",
              "list_price        6720\n",
              "inv_ship_days      133\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lCCJjJWqGLvU"
      },
      "source": [
        "## import return label data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cYVtnDc2HXFA"
      },
      "source": [
        "## import fraud data\n",
        "file = path + 'frauds.csv'\n",
        "df_fraud = pd.read_csv(file,header=None)\n",
        "df_fraud.columns = ['invoice_no']"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YntiE6PVIrPC"
      },
      "source": [
        "## import return new labeled data\n",
        "file = path + 'return.csv'\n",
        "df_fraud2 = pd.read_csv(file,header=None)\n",
        "df_fraud2.columns = ['invoice_no']"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CiNt30SZf6aD",
        "outputId": "9ad2d057-388f-4348-b8d4-89c9b1d3c26e"
      },
      "source": [
        "len(df_fraud2)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bo6Q08-CJyOv"
      },
      "source": [
        "def label_fraud(df, df_fraud, df_fraud2):\n",
        "  df['fraud'] = np.zeros(len(df))\n",
        "  frauds_l = df_fraud['invoice_no'].to_list()\n",
        "  frauds_l2 = df_fraud2['invoice_no'].to_list()\n",
        "  df.loc[df['invoice_no'].isin(frauds_l),'fraud'] = 1\n",
        "  df.loc[df['invoice_no'].isin(frauds_l2),'fraud'] = 2\n",
        "  return df"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y0iwhuZ_XIpE"
      },
      "source": [
        "df = label_fraud(df, df_fraud,df_fraud2)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S6y811N2NJZS",
        "outputId": "4a05289e-b7e3-407b-e8a4-3fccd22e35f2"
      },
      "source": [
        "df['fraud'].value_counts()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0    228014\n",
              "2.0       433\n",
              "1.0       154\n",
              "Name: fraud, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zYRaXHXsP07P"
      },
      "source": [
        "## Resampling to address the imbalance class\n",
        "Because fraud labels are given to invoice level, need to keep records of same invoice together. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d7PpSBXyT1iz"
      },
      "source": [
        "df_fraud = df[df['fraud'] == 1]\n",
        "df_non_fraud = df[df['fraud'] == 0]\n",
        "df_fraud2 = df[df['fraud'] == 2]"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eGH1pJ_JVnr7",
        "outputId": "1b2450fe-0cad-4483-b6b9-788a7d84a7b3"
      },
      "source": [
        "df_fraud2.info()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 433 entries, 19646 to 217825\n",
            "Data columns (total 17 columns):\n",
            " #   Column         Non-Null Count  Dtype  \n",
            "---  ------         --------------  -----  \n",
            " 0   distributor    433 non-null    object \n",
            " 1   sales          433 non-null    object \n",
            " 2   branch         433 non-null    int64  \n",
            " 3   inv_type       433 non-null    object \n",
            " 4   invoice_no     433 non-null    int64  \n",
            " 5   product_no     433 non-null    object \n",
            " 6   prod_cla       433 non-null    float64\n",
            " 7   qty            433 non-null    int64  \n",
            " 8   total_amt      433 non-null    float64\n",
            " 9   sale_price     433 non-null    float64\n",
            " 10  ship_qty       433 non-null    int64  \n",
            " 11  cust_type      433 non-null    object \n",
            " 12  return         433 non-null    int64  \n",
            " 13  discount_app   433 non-null    int64  \n",
            " 14  list_price     433 non-null    float64\n",
            " 15  inv_ship_days  433 non-null    int64  \n",
            " 16  fraud          433 non-null    float64\n",
            "dtypes: float64(5), int64(7), object(5)\n",
            "memory usage: 60.9+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M2L3ePEOXvyD"
      },
      "source": [
        "def sampling_inv(df_non_fraud):\n",
        "  '''\n",
        "  Random sampling from unlabled invoices.\n",
        "  '''\n",
        "  sample_inv = df_non_fraud['invoice_no'].unique()\n",
        "  print(len(sample_inv))\n",
        "  sample_inv1 = np.random.choice(sample_inv,size=1000,replace=False)\n",
        "  sample_inv = np.setdiff1d(sample_inv,sample_inv1)\n",
        "  print(len(sample_inv))\n",
        "  sample_inv2 = np.random.choice(sample_inv,size=5000,replace=False)\n",
        "  sample_inv = np.setdiff1d(sample_inv,sample_inv2)\n",
        "  print(len(sample_inv))\n",
        "  return sample_inv1, sample_inv2, sample_inv\n"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l_tDCpKgY1W-",
        "outputId": "529b2cf8-356d-4191-c11c-0c55793fcb67"
      },
      "source": [
        "sample_inv1, sample_inv2, sample_inv = sampling_inv(df_non_fraud)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "30686\n",
            "29686\n",
            "24686\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aFm7Iw2VepcP",
        "outputId": "f94d6781-10d3-4f97-83bd-a204ba8f3042"
      },
      "source": [
        "len(np.unique(sample_inv2))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5000"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Js8R7sDr7BM"
      },
      "source": [
        "## Build training dataset\n",
        "df_train = df_non_fraud[df_non_fraud['invoice_no'].isin(sample_inv2)]\n",
        "df_train = pd.concat([df_train,df_fraud2])\n",
        "df_train.loc[df_train['fraud'] == 2, 'fraud'] = 1 \n",
        "df_train = df_train.sort_index()"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O01agYImtUx9"
      },
      "source": [
        "## Build eval dataset\n",
        "df_test = df_non_fraud[df_non_fraud['invoice_no'].isin(sample_inv1)]\n",
        "df_test = pd.concat([df_test,df_fraud])\n",
        "df_test = df_test.sort_index()"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pzKw_DggxMS-",
        "outputId": "0d02b1b3-6fee-4424-a5ef-0ce6652c48a4"
      },
      "source": [
        "df_train.shape"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(37232, 17)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HqJlSiFlRwXl",
        "outputId": "e9ba5409-dd45-4a43-fe9a-ff6525e44e6b"
      },
      "source": [
        "df_test.shape"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7465, 17)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V_LOYj9ZZne0",
        "outputId": "59500217-5543-494e-c7f4-196dc9b7e621"
      },
      "source": [
        "df_train.info()"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 37232 entries, 108 to 228534\n",
            "Data columns (total 17 columns):\n",
            " #   Column         Non-Null Count  Dtype  \n",
            "---  ------         --------------  -----  \n",
            " 0   distributor    37232 non-null  object \n",
            " 1   sales          37232 non-null  object \n",
            " 2   branch         37232 non-null  int64  \n",
            " 3   inv_type       37232 non-null  object \n",
            " 4   invoice_no     37232 non-null  int64  \n",
            " 5   product_no     37232 non-null  object \n",
            " 6   prod_cla       37232 non-null  float64\n",
            " 7   qty            37232 non-null  int64  \n",
            " 8   total_amt      37232 non-null  float64\n",
            " 9   sale_price     37232 non-null  float64\n",
            " 10  ship_qty       37232 non-null  int64  \n",
            " 11  cust_type      37232 non-null  object \n",
            " 12  return         37232 non-null  int64  \n",
            " 13  discount_app   37232 non-null  int64  \n",
            " 14  list_price     37232 non-null  float64\n",
            " 15  inv_ship_days  37232 non-null  int64  \n",
            " 16  fraud          37232 non-null  float64\n",
            "dtypes: float64(5), int64(7), object(5)\n",
            "memory usage: 5.1+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l7OnGZt9GEAL"
      },
      "source": [
        "## Encoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T0O7sPin33OP"
      },
      "source": [
        "cols = df.columns.to_list()\n",
        "cols = ['distributor', 'sales', 'branch', 'inv_type', 'invoice_no', 'product_no', 'prod_cla', 'cust_type']"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "486mzoZj2LsQ"
      },
      "source": [
        "def field_encoding(df_train, df_eval):\n",
        "  '''\n",
        "  Ordinal encode categorical fields.\n",
        "  '''\n",
        "  cols = ['distributor', 'sales', 'branch', 'inv_type', 'invoice_no', 'product_no', 'prod_cla', 'cust_type']\n",
        "  df_train[cols] = df_train[cols].astype('str') \n",
        "  df_test[cols] = df_test[cols].astype('str') \n",
        "  df1 = pd.concat([df_train, df_test])\n",
        "  enc = LabelEncoder()\n",
        "  for f in cols:\n",
        "    enc.fit(df1[f])\n",
        "    df_train[f] = enc.transform(df_train[f])\n",
        "    df_test[f] = enc.transform(df_test[f])\n",
        "  return df_train, df_test"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qgVnIE3j7G0X"
      },
      "source": [
        "X_train = df_train.copy()\n",
        "X_test = df_test.copy()\n",
        "X_train, X_test = field_encoding(X_train, X_test)"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PdzuM0U2jb9V",
        "outputId": "77a74b01-e851-4496-c2ac-6c905b07e7ee"
      },
      "source": [
        "print(len(X_test),len(X_train))"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7465 37232\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A7gwzMqo8zkK",
        "outputId": "600249d0-31ff-4981-feae-8959d13f79a0"
      },
      "source": [
        "X_train.nunique()"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "distributor       518\n",
              "sales             187\n",
              "branch             28\n",
              "inv_type            3\n",
              "invoice_no       5024\n",
              "product_no        785\n",
              "prod_cla            7\n",
              "qty                89\n",
              "total_amt        5363\n",
              "sale_price       3725\n",
              "ship_qty           90\n",
              "cust_type          20\n",
              "return              2\n",
              "discount_app        2\n",
              "list_price       3012\n",
              "inv_ship_days      75\n",
              "fraud               2\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gDkexYmPxM8O"
      },
      "source": [
        "## Standardscale data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wxt4dsJo7tDa"
      },
      "source": [
        "scaler = StandardScaler()"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YeeK6JNC8Fqz"
      },
      "source": [
        "y_train = X_train['fraud'].values\n",
        "X_train = X_train.drop(columns=['fraud'])\n",
        "\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "y_train = y_train.reshape(len(y_train),1)"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "86joAZPl9YpL"
      },
      "source": [
        "y_test = X_test['fraud'].values\n",
        "X_test = X_test.drop(columns=['fraud'])\n",
        "\n",
        "X_test = scaler.transform(X_test)\n",
        "y_test = y_test.reshape(len(y_test),1)"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MNUBFns291Qv",
        "outputId": "21674f79-4e99-4b2e-ab55-1fc39c8682da"
      },
      "source": [
        "X_train[0]"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.31969424,  0.81761482, -1.18807636,  0.01829786, -1.70644042,\n",
              "        1.7724664 , -0.0709056 , -0.00639322,  1.28657546,  3.27756406,\n",
              "        0.0045258 , -0.77624262, -0.0163908 ,  0.01036562,  3.27549634,\n",
              "       -0.06245374])"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4o9UXO0--hgv",
        "outputId": "a17586c3-7590-4424-91e9-fc21f2605af4"
      },
      "source": [
        "y_test.shape"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7465, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gMv9MH5QVu6B",
        "outputId": "9b46608e-75f2-4ad9-d46c-fc21da3cad8f"
      },
      "source": [
        "y_train.sum()"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "433.0"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vnO2HnA4_RQU"
      },
      "source": [
        "## Build model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "09WCa-Qn_T0G"
      },
      "source": [
        "# define the  model\n",
        "def build_model():\n",
        "  model = Sequential()\n",
        "  model.add(Dense(32, input_dim=X_train.shape[1], activation='relu', kernel_initializer='he_normal'))\n",
        "  model.add(Dense(16,activation='relu'))\n",
        "  model.add(Dense(1, activation='sigmoid'))\n",
        "  # compile the keras model\n",
        "  opt = tf.keras.optimizers.Adam(clipnorm=1, learning_rate=0.0001)\n",
        "  model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
        "  return model"
      ],
      "execution_count": 158,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pBs2KuNeAErs",
        "outputId": "5da98c3a-810d-48b2-bad7-ec8163bb960e"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 64)                1088      \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 3,201\n",
            "Trainable params: 3,201\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cfEQ-OXDA3mV"
      },
      "source": [
        "## Training model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "413m67NPZY4F",
        "outputId": "174c1463-e259-4dfb-e0ca-a0cb4dcdc6b1"
      },
      "source": [
        "## clear previous model.  Make sure training from 0. \n",
        "del model\n",
        "clear_session()\n",
        "tf.compat.v1.reset_default_graph()\n",
        "reset_seeds()\n",
        "model = build_model()"
      ],
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RANDOM SEEDS RESET\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pp9q-HK4A6UX",
        "outputId": "08d054af-045c-498e-d2d8-040e9540ee7b"
      },
      "source": [
        "model.fit(X_train, y_train, epochs=500,batch_size=64,class_weight={0:5, 1:30000})"
      ],
      "execution_count": 177,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 266.1814 - accuracy: 0.9985\n",
            "Epoch 2/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 275.9715 - accuracy: 0.9984\n",
            "Epoch 3/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 267.7177 - accuracy: 0.9985\n",
            "Epoch 4/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 265.9082 - accuracy: 0.9986\n",
            "Epoch 5/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 258.0906 - accuracy: 0.9986\n",
            "Epoch 6/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 270.6037 - accuracy: 0.9986\n",
            "Epoch 7/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 264.3226 - accuracy: 0.9984\n",
            "Epoch 8/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 258.8331 - accuracy: 0.9985\n",
            "Epoch 9/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 258.2766 - accuracy: 0.9986\n",
            "Epoch 10/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 263.8288 - accuracy: 0.9985\n",
            "Epoch 11/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 267.1692 - accuracy: 0.9985\n",
            "Epoch 12/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 259.7840 - accuracy: 0.9984\n",
            "Epoch 13/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 267.8335 - accuracy: 0.9985\n",
            "Epoch 14/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 264.2847 - accuracy: 0.9986\n",
            "Epoch 15/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 265.3573 - accuracy: 0.9985\n",
            "Epoch 16/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 258.5822 - accuracy: 0.9985\n",
            "Epoch 17/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 263.6761 - accuracy: 0.9987\n",
            "Epoch 18/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 258.7490 - accuracy: 0.9985\n",
            "Epoch 19/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 265.5029 - accuracy: 0.9987\n",
            "Epoch 20/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 254.2214 - accuracy: 0.9986\n",
            "Epoch 21/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 270.7083 - accuracy: 0.9985\n",
            "Epoch 22/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 264.8910 - accuracy: 0.9986\n",
            "Epoch 23/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 257.7613 - accuracy: 0.9985\n",
            "Epoch 24/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 261.9475 - accuracy: 0.9986\n",
            "Epoch 25/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 267.9248 - accuracy: 0.9987\n",
            "Epoch 26/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 261.8357 - accuracy: 0.9985\n",
            "Epoch 27/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 267.0562 - accuracy: 0.9985\n",
            "Epoch 28/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 266.9583 - accuracy: 0.9986\n",
            "Epoch 29/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 261.4452 - accuracy: 0.9985\n",
            "Epoch 30/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 263.0006 - accuracy: 0.9986\n",
            "Epoch 31/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 267.0431 - accuracy: 0.9986\n",
            "Epoch 32/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 261.7154 - accuracy: 0.9987\n",
            "Epoch 33/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 254.3653 - accuracy: 0.9986\n",
            "Epoch 34/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 252.0471 - accuracy: 0.9984\n",
            "Epoch 35/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 254.9982 - accuracy: 0.9985\n",
            "Epoch 36/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 253.2911 - accuracy: 0.9986\n",
            "Epoch 37/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 256.9081 - accuracy: 0.9986\n",
            "Epoch 38/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 255.1301 - accuracy: 0.9987\n",
            "Epoch 39/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 253.8301 - accuracy: 0.9985\n",
            "Epoch 40/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 249.6304 - accuracy: 0.9986\n",
            "Epoch 41/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 254.0071 - accuracy: 0.9986\n",
            "Epoch 42/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 247.2023 - accuracy: 0.9987\n",
            "Epoch 43/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 251.4569 - accuracy: 0.9986\n",
            "Epoch 44/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 252.0382 - accuracy: 0.9986\n",
            "Epoch 45/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 248.9722 - accuracy: 0.9987\n",
            "Epoch 46/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 247.7694 - accuracy: 0.9985\n",
            "Epoch 47/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 255.7600 - accuracy: 0.9987\n",
            "Epoch 48/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 252.5041 - accuracy: 0.9986\n",
            "Epoch 49/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 252.9325 - accuracy: 0.9985\n",
            "Epoch 50/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 252.8639 - accuracy: 0.9987\n",
            "Epoch 51/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 248.1520 - accuracy: 0.9986\n",
            "Epoch 52/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 248.6139 - accuracy: 0.9985\n",
            "Epoch 53/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 254.4250 - accuracy: 0.9986\n",
            "Epoch 54/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 247.2045 - accuracy: 0.9985\n",
            "Epoch 55/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 244.9269 - accuracy: 0.9986\n",
            "Epoch 56/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 242.3575 - accuracy: 0.9985\n",
            "Epoch 57/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 247.5158 - accuracy: 0.9986\n",
            "Epoch 58/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 258.4640 - accuracy: 0.9986\n",
            "Epoch 59/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 252.6108 - accuracy: 0.9986\n",
            "Epoch 60/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 245.8098 - accuracy: 0.9986\n",
            "Epoch 61/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 249.0041 - accuracy: 0.9986\n",
            "Epoch 62/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 254.5201 - accuracy: 0.9986\n",
            "Epoch 63/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 257.8980 - accuracy: 0.9986\n",
            "Epoch 64/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 248.2742 - accuracy: 0.9985\n",
            "Epoch 65/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 244.7490 - accuracy: 0.9987\n",
            "Epoch 66/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 254.2303 - accuracy: 0.9986\n",
            "Epoch 67/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 251.1536 - accuracy: 0.9986\n",
            "Epoch 68/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 246.7473 - accuracy: 0.9985\n",
            "Epoch 69/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 247.7827 - accuracy: 0.9986\n",
            "Epoch 70/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 252.0456 - accuracy: 0.9986\n",
            "Epoch 71/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 248.7354 - accuracy: 0.9985\n",
            "Epoch 72/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 244.5002 - accuracy: 0.9985\n",
            "Epoch 73/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 250.7983 - accuracy: 0.9986\n",
            "Epoch 74/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 248.2035 - accuracy: 0.9985\n",
            "Epoch 75/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 244.4976 - accuracy: 0.9986\n",
            "Epoch 76/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 245.4914 - accuracy: 0.9986\n",
            "Epoch 77/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 244.0992 - accuracy: 0.9985\n",
            "Epoch 78/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 239.7765 - accuracy: 0.9986\n",
            "Epoch 79/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 245.3805 - accuracy: 0.9986\n",
            "Epoch 80/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 236.5293 - accuracy: 0.9986\n",
            "Epoch 81/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 234.3111 - accuracy: 0.9986\n",
            "Epoch 82/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 253.7038 - accuracy: 0.9987\n",
            "Epoch 83/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 235.1484 - accuracy: 0.9986\n",
            "Epoch 84/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 239.7378 - accuracy: 0.9987\n",
            "Epoch 85/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 243.8067 - accuracy: 0.9986\n",
            "Epoch 86/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 240.3816 - accuracy: 0.9986\n",
            "Epoch 87/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 240.4464 - accuracy: 0.9986\n",
            "Epoch 88/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 240.6600 - accuracy: 0.9986\n",
            "Epoch 89/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 238.9427 - accuracy: 0.9987\n",
            "Epoch 90/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 241.2527 - accuracy: 0.9987\n",
            "Epoch 91/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 236.9668 - accuracy: 0.9987\n",
            "Epoch 92/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 231.4231 - accuracy: 0.9987\n",
            "Epoch 93/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 237.3452 - accuracy: 0.9985\n",
            "Epoch 94/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 244.2389 - accuracy: 0.9987\n",
            "Epoch 95/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 229.1964 - accuracy: 0.9985\n",
            "Epoch 96/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 233.3950 - accuracy: 0.9988\n",
            "Epoch 97/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 236.4967 - accuracy: 0.9985\n",
            "Epoch 98/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 230.6825 - accuracy: 0.9988\n",
            "Epoch 99/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 236.5840 - accuracy: 0.9986\n",
            "Epoch 100/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 227.9917 - accuracy: 0.9987\n",
            "Epoch 101/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 232.0375 - accuracy: 0.9987\n",
            "Epoch 102/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 227.8391 - accuracy: 0.9987\n",
            "Epoch 103/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 230.4412 - accuracy: 0.9987\n",
            "Epoch 104/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 232.5630 - accuracy: 0.9987\n",
            "Epoch 105/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 225.9523 - accuracy: 0.9987\n",
            "Epoch 106/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 229.3306 - accuracy: 0.9987\n",
            "Epoch 107/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 231.8523 - accuracy: 0.9987\n",
            "Epoch 108/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 225.2092 - accuracy: 0.9987\n",
            "Epoch 109/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 235.9392 - accuracy: 0.9987\n",
            "Epoch 110/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 228.8165 - accuracy: 0.9987\n",
            "Epoch 111/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 230.8778 - accuracy: 0.9986\n",
            "Epoch 112/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 229.5928 - accuracy: 0.9988\n",
            "Epoch 113/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 218.6519 - accuracy: 0.9986\n",
            "Epoch 114/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 219.4817 - accuracy: 0.9987\n",
            "Epoch 115/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 226.7534 - accuracy: 0.9987\n",
            "Epoch 116/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 221.6412 - accuracy: 0.9986\n",
            "Epoch 117/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 220.7682 - accuracy: 0.9987\n",
            "Epoch 118/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 223.9362 - accuracy: 0.9987\n",
            "Epoch 119/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 214.7974 - accuracy: 0.9986\n",
            "Epoch 120/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 213.3779 - accuracy: 0.9987\n",
            "Epoch 121/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 231.1819 - accuracy: 0.9988\n",
            "Epoch 122/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 228.5817 - accuracy: 0.9987\n",
            "Epoch 123/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 218.7650 - accuracy: 0.9987\n",
            "Epoch 124/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 230.5608 - accuracy: 0.9987\n",
            "Epoch 125/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 227.0478 - accuracy: 0.9987\n",
            "Epoch 126/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 218.3800 - accuracy: 0.9988\n",
            "Epoch 127/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 220.1070 - accuracy: 0.9987\n",
            "Epoch 128/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 222.0142 - accuracy: 0.9987\n",
            "Epoch 129/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 228.3202 - accuracy: 0.9988\n",
            "Epoch 130/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 211.3653 - accuracy: 0.9987\n",
            "Epoch 131/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 225.9332 - accuracy: 0.9987\n",
            "Epoch 132/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 220.3703 - accuracy: 0.9987\n",
            "Epoch 133/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 225.3654 - accuracy: 0.9988\n",
            "Epoch 134/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 221.5766 - accuracy: 0.9988\n",
            "Epoch 135/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 226.5612 - accuracy: 0.9988\n",
            "Epoch 136/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 226.3257 - accuracy: 0.9987\n",
            "Epoch 137/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 218.4112 - accuracy: 0.9987\n",
            "Epoch 138/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 222.2333 - accuracy: 0.9988\n",
            "Epoch 139/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 217.2591 - accuracy: 0.9988\n",
            "Epoch 140/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 223.8441 - accuracy: 0.9988\n",
            "Epoch 141/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 219.1454 - accuracy: 0.9987\n",
            "Epoch 142/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 220.8350 - accuracy: 0.9987\n",
            "Epoch 143/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 221.4726 - accuracy: 0.9988\n",
            "Epoch 144/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 216.0878 - accuracy: 0.9988\n",
            "Epoch 145/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 220.5043 - accuracy: 0.9988\n",
            "Epoch 146/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 217.2815 - accuracy: 0.9987\n",
            "Epoch 147/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 224.2650 - accuracy: 0.9987\n",
            "Epoch 148/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 221.9304 - accuracy: 0.9987\n",
            "Epoch 149/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 219.4086 - accuracy: 0.9987\n",
            "Epoch 150/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 216.7030 - accuracy: 0.9988\n",
            "Epoch 151/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 213.7934 - accuracy: 0.9987\n",
            "Epoch 152/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 210.2798 - accuracy: 0.9988\n",
            "Epoch 153/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 215.9064 - accuracy: 0.9987\n",
            "Epoch 154/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 220.4668 - accuracy: 0.9987\n",
            "Epoch 155/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 218.9912 - accuracy: 0.9988\n",
            "Epoch 156/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 219.1830 - accuracy: 0.9988\n",
            "Epoch 157/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 220.5566 - accuracy: 0.9988\n",
            "Epoch 158/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 216.2476 - accuracy: 0.9987\n",
            "Epoch 159/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 221.5237 - accuracy: 0.9988\n",
            "Epoch 160/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 208.5063 - accuracy: 0.9988\n",
            "Epoch 161/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 217.9017 - accuracy: 0.9987\n",
            "Epoch 162/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 213.0006 - accuracy: 0.9988\n",
            "Epoch 163/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 219.7483 - accuracy: 0.9988\n",
            "Epoch 164/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 208.5185 - accuracy: 0.9987\n",
            "Epoch 165/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 219.1976 - accuracy: 0.9987\n",
            "Epoch 166/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 218.5287 - accuracy: 0.9988\n",
            "Epoch 167/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 214.1253 - accuracy: 0.9988\n",
            "Epoch 168/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 214.4555 - accuracy: 0.9988\n",
            "Epoch 169/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 216.7980 - accuracy: 0.9988\n",
            "Epoch 170/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 220.6109 - accuracy: 0.9987\n",
            "Epoch 171/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 211.0574 - accuracy: 0.9988\n",
            "Epoch 172/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 208.6027 - accuracy: 0.9988\n",
            "Epoch 173/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 224.5843 - accuracy: 0.9988\n",
            "Epoch 174/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 212.2775 - accuracy: 0.9989\n",
            "Epoch 175/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 215.5748 - accuracy: 0.9988\n",
            "Epoch 176/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 209.1655 - accuracy: 0.9990\n",
            "Epoch 177/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 217.7917 - accuracy: 0.9988\n",
            "Epoch 178/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 220.8541 - accuracy: 0.9988\n",
            "Epoch 179/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 210.3670 - accuracy: 0.9988\n",
            "Epoch 180/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 209.9762 - accuracy: 0.9989\n",
            "Epoch 181/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 219.2484 - accuracy: 0.9988\n",
            "Epoch 182/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 208.6493 - accuracy: 0.9987\n",
            "Epoch 183/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 216.5049 - accuracy: 0.9988\n",
            "Epoch 184/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 203.0817 - accuracy: 0.9988\n",
            "Epoch 185/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 212.5460 - accuracy: 0.9987\n",
            "Epoch 186/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 212.4906 - accuracy: 0.9988\n",
            "Epoch 187/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 202.5413 - accuracy: 0.9987\n",
            "Epoch 188/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 212.8836 - accuracy: 0.9988\n",
            "Epoch 189/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 206.5496 - accuracy: 0.9988\n",
            "Epoch 190/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 203.0282 - accuracy: 0.9987\n",
            "Epoch 191/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 207.9441 - accuracy: 0.9988\n",
            "Epoch 192/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 210.4904 - accuracy: 0.9989\n",
            "Epoch 193/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 209.0755 - accuracy: 0.9988\n",
            "Epoch 194/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 207.3566 - accuracy: 0.9989\n",
            "Epoch 195/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 207.2209 - accuracy: 0.9988\n",
            "Epoch 196/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 207.3071 - accuracy: 0.9988\n",
            "Epoch 197/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 210.9044 - accuracy: 0.9988\n",
            "Epoch 198/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 213.0073 - accuracy: 0.9988\n",
            "Epoch 199/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 205.1177 - accuracy: 0.9989\n",
            "Epoch 200/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 206.7919 - accuracy: 0.9988\n",
            "Epoch 201/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 207.8784 - accuracy: 0.9988\n",
            "Epoch 202/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 214.1009 - accuracy: 0.9988\n",
            "Epoch 203/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 208.9963 - accuracy: 0.9988\n",
            "Epoch 204/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 206.9467 - accuracy: 0.9989\n",
            "Epoch 205/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 201.9904 - accuracy: 0.9989\n",
            "Epoch 206/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 204.0701 - accuracy: 0.9988\n",
            "Epoch 207/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 210.6927 - accuracy: 0.9988\n",
            "Epoch 208/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 212.4553 - accuracy: 0.9988\n",
            "Epoch 209/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 210.4836 - accuracy: 0.9989\n",
            "Epoch 210/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 203.0914 - accuracy: 0.9989\n",
            "Epoch 211/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 206.9634 - accuracy: 0.9988\n",
            "Epoch 212/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 203.3558 - accuracy: 0.9988\n",
            "Epoch 213/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 213.5427 - accuracy: 0.9988\n",
            "Epoch 214/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 209.2788 - accuracy: 0.9989\n",
            "Epoch 215/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 206.4417 - accuracy: 0.9988\n",
            "Epoch 216/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 200.7677 - accuracy: 0.9989\n",
            "Epoch 217/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 215.1234 - accuracy: 0.9988\n",
            "Epoch 218/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 207.8562 - accuracy: 0.9989\n",
            "Epoch 219/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 201.8620 - accuracy: 0.9988\n",
            "Epoch 220/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 206.8103 - accuracy: 0.9988\n",
            "Epoch 221/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 205.0110 - accuracy: 0.9988\n",
            "Epoch 222/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 208.5010 - accuracy: 0.9989\n",
            "Epoch 223/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 202.9667 - accuracy: 0.9988\n",
            "Epoch 224/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 205.9507 - accuracy: 0.9989\n",
            "Epoch 225/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 210.3798 - accuracy: 0.9988\n",
            "Epoch 226/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 209.8546 - accuracy: 0.9988\n",
            "Epoch 227/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 203.3661 - accuracy: 0.9988\n",
            "Epoch 228/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 210.3179 - accuracy: 0.9989\n",
            "Epoch 229/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 207.4813 - accuracy: 0.9989\n",
            "Epoch 230/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 204.9104 - accuracy: 0.9989\n",
            "Epoch 231/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 210.7805 - accuracy: 0.9988\n",
            "Epoch 232/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 204.7965 - accuracy: 0.9989\n",
            "Epoch 233/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 204.4537 - accuracy: 0.9989\n",
            "Epoch 234/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 209.5513 - accuracy: 0.9988\n",
            "Epoch 235/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 203.9938 - accuracy: 0.9989\n",
            "Epoch 236/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 202.2211 - accuracy: 0.9989\n",
            "Epoch 237/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 215.2634 - accuracy: 0.9988\n",
            "Epoch 238/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 205.7913 - accuracy: 0.9989\n",
            "Epoch 239/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 206.6318 - accuracy: 0.9989\n",
            "Epoch 240/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 202.9091 - accuracy: 0.9988\n",
            "Epoch 241/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 204.9543 - accuracy: 0.9989\n",
            "Epoch 242/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 205.5038 - accuracy: 0.9988\n",
            "Epoch 243/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 210.8756 - accuracy: 0.9989\n",
            "Epoch 244/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 188.7776 - accuracy: 0.9989\n",
            "Epoch 245/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 201.2569 - accuracy: 0.9989\n",
            "Epoch 246/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 208.7908 - accuracy: 0.9989\n",
            "Epoch 247/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 202.9105 - accuracy: 0.9989\n",
            "Epoch 248/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 208.8329 - accuracy: 0.9988\n",
            "Epoch 249/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 201.4233 - accuracy: 0.9990\n",
            "Epoch 250/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 208.6498 - accuracy: 0.9989\n",
            "Epoch 251/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 209.4514 - accuracy: 0.9990\n",
            "Epoch 252/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 204.7544 - accuracy: 0.9989\n",
            "Epoch 253/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 201.9565 - accuracy: 0.9990\n",
            "Epoch 254/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 204.2026 - accuracy: 0.9989\n",
            "Epoch 255/500\n",
            "582/582 [==============================] - 2s 3ms/step - loss: 200.8537 - accuracy: 0.9989\n",
            "Epoch 256/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 208.2249 - accuracy: 0.9989\n",
            "Epoch 257/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 202.7810 - accuracy: 0.9989\n",
            "Epoch 258/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 203.4892 - accuracy: 0.9988\n",
            "Epoch 259/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 199.1224 - accuracy: 0.9989\n",
            "Epoch 260/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 204.6741 - accuracy: 0.9989\n",
            "Epoch 261/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 203.5608 - accuracy: 0.9989\n",
            "Epoch 262/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 202.9896 - accuracy: 0.9989\n",
            "Epoch 263/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 205.6937 - accuracy: 0.9990\n",
            "Epoch 264/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 201.0928 - accuracy: 0.9989\n",
            "Epoch 265/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 201.2789 - accuracy: 0.9989\n",
            "Epoch 266/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 206.9597 - accuracy: 0.9988\n",
            "Epoch 267/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 205.0612 - accuracy: 0.9989\n",
            "Epoch 268/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 203.4420 - accuracy: 0.9989\n",
            "Epoch 269/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 204.7427 - accuracy: 0.9989\n",
            "Epoch 270/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 196.0062 - accuracy: 0.9990\n",
            "Epoch 271/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 207.0128 - accuracy: 0.9989\n",
            "Epoch 272/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 202.8236 - accuracy: 0.9990\n",
            "Epoch 273/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 200.2930 - accuracy: 0.9988\n",
            "Epoch 274/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 205.7554 - accuracy: 0.9989\n",
            "Epoch 275/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 206.3210 - accuracy: 0.9989\n",
            "Epoch 276/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 208.7208 - accuracy: 0.9989\n",
            "Epoch 277/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 207.4416 - accuracy: 0.9989\n",
            "Epoch 278/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 202.7212 - accuracy: 0.9989\n",
            "Epoch 279/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 198.6123 - accuracy: 0.9989\n",
            "Epoch 280/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 199.5645 - accuracy: 0.9989\n",
            "Epoch 281/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 203.6564 - accuracy: 0.9989\n",
            "Epoch 282/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 200.4801 - accuracy: 0.9989\n",
            "Epoch 283/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 201.7599 - accuracy: 0.9990\n",
            "Epoch 284/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 199.3308 - accuracy: 0.9989\n",
            "Epoch 285/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 208.2974 - accuracy: 0.9989\n",
            "Epoch 286/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 198.7531 - accuracy: 0.9989\n",
            "Epoch 287/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 204.5212 - accuracy: 0.9990\n",
            "Epoch 288/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 203.3979 - accuracy: 0.9989\n",
            "Epoch 289/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 205.5287 - accuracy: 0.9990\n",
            "Epoch 290/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 203.7448 - accuracy: 0.9990\n",
            "Epoch 291/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 205.7325 - accuracy: 0.9989\n",
            "Epoch 292/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 202.4834 - accuracy: 0.9989\n",
            "Epoch 293/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 203.3264 - accuracy: 0.9989\n",
            "Epoch 294/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 198.3681 - accuracy: 0.9989\n",
            "Epoch 295/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 204.5243 - accuracy: 0.9989\n",
            "Epoch 296/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 201.2609 - accuracy: 0.9989\n",
            "Epoch 297/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 201.8559 - accuracy: 0.9989\n",
            "Epoch 298/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 194.1731 - accuracy: 0.9990\n",
            "Epoch 299/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 207.8388 - accuracy: 0.9989\n",
            "Epoch 300/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 196.3932 - accuracy: 0.9989\n",
            "Epoch 301/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 196.3310 - accuracy: 0.9989\n",
            "Epoch 302/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 209.3935 - accuracy: 0.9989\n",
            "Epoch 303/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 197.1372 - accuracy: 0.9990\n",
            "Epoch 304/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 192.1297 - accuracy: 0.9989\n",
            "Epoch 305/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 200.3813 - accuracy: 0.9990\n",
            "Epoch 306/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 199.8701 - accuracy: 0.9989\n",
            "Epoch 307/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 202.2552 - accuracy: 0.9988\n",
            "Epoch 308/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 200.3517 - accuracy: 0.9990\n",
            "Epoch 309/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 200.2833 - accuracy: 0.9989\n",
            "Epoch 310/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 202.4779 - accuracy: 0.9989\n",
            "Epoch 311/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 206.2080 - accuracy: 0.9988\n",
            "Epoch 312/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 199.4666 - accuracy: 0.9989\n",
            "Epoch 313/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 196.1395 - accuracy: 0.9990\n",
            "Epoch 314/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 201.5561 - accuracy: 0.9989\n",
            "Epoch 315/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 201.1546 - accuracy: 0.9989\n",
            "Epoch 316/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 194.9701 - accuracy: 0.9989\n",
            "Epoch 317/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 204.5401 - accuracy: 0.9990\n",
            "Epoch 318/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 196.4472 - accuracy: 0.9989\n",
            "Epoch 319/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 198.6570 - accuracy: 0.9989\n",
            "Epoch 320/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 196.6969 - accuracy: 0.9990\n",
            "Epoch 321/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 200.7809 - accuracy: 0.9989\n",
            "Epoch 322/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 193.6552 - accuracy: 0.9989\n",
            "Epoch 323/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 192.9614 - accuracy: 0.9988\n",
            "Epoch 324/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 195.4770 - accuracy: 0.9989\n",
            "Epoch 325/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 196.7661 - accuracy: 0.9989\n",
            "Epoch 326/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 190.0316 - accuracy: 0.9989\n",
            "Epoch 327/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 194.4956 - accuracy: 0.9990\n",
            "Epoch 328/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 193.6090 - accuracy: 0.9988\n",
            "Epoch 329/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 195.6217 - accuracy: 0.9990\n",
            "Epoch 330/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 196.6604 - accuracy: 0.9989\n",
            "Epoch 331/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 198.7775 - accuracy: 0.9989\n",
            "Epoch 332/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 195.0411 - accuracy: 0.9989\n",
            "Epoch 333/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 191.8780 - accuracy: 0.9989\n",
            "Epoch 334/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 193.1990 - accuracy: 0.9990\n",
            "Epoch 335/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 196.3126 - accuracy: 0.9989\n",
            "Epoch 336/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 193.0892 - accuracy: 0.9990\n",
            "Epoch 337/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 194.1410 - accuracy: 0.9989\n",
            "Epoch 338/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 184.6193 - accuracy: 0.9990\n",
            "Epoch 339/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 199.6064 - accuracy: 0.9990\n",
            "Epoch 340/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 187.9881 - accuracy: 0.9990\n",
            "Epoch 341/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 198.1606 - accuracy: 0.9990\n",
            "Epoch 342/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 188.5165 - accuracy: 0.9990\n",
            "Epoch 343/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 187.2712 - accuracy: 0.9990\n",
            "Epoch 344/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 191.0029 - accuracy: 0.9989\n",
            "Epoch 345/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 187.7110 - accuracy: 0.9989\n",
            "Epoch 346/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 187.7066 - accuracy: 0.9990\n",
            "Epoch 347/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 198.1915 - accuracy: 0.9989\n",
            "Epoch 348/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 188.6007 - accuracy: 0.9990\n",
            "Epoch 349/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 188.1004 - accuracy: 0.9990\n",
            "Epoch 350/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 189.6756 - accuracy: 0.9989\n",
            "Epoch 351/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 190.3539 - accuracy: 0.9989\n",
            "Epoch 352/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 184.4292 - accuracy: 0.9989\n",
            "Epoch 353/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 197.2932 - accuracy: 0.9990\n",
            "Epoch 354/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 191.0354 - accuracy: 0.9989\n",
            "Epoch 355/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 193.2235 - accuracy: 0.9989\n",
            "Epoch 356/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 194.1810 - accuracy: 0.9990\n",
            "Epoch 357/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 194.8584 - accuracy: 0.9989\n",
            "Epoch 358/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 193.2085 - accuracy: 0.9990\n",
            "Epoch 359/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 192.9916 - accuracy: 0.9989\n",
            "Epoch 360/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 194.8598 - accuracy: 0.9989\n",
            "Epoch 361/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 187.5063 - accuracy: 0.9989\n",
            "Epoch 362/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 192.7822 - accuracy: 0.9990\n",
            "Epoch 363/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 186.9038 - accuracy: 0.9989\n",
            "Epoch 364/500\n",
            "582/582 [==============================] - 1s 3ms/step - loss: 192.8091 - accuracy: 0.9989\n",
            "Epoch 365/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 196.3285 - accuracy: 0.9989\n",
            "Epoch 366/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 188.8267 - accuracy: 0.9989\n",
            "Epoch 367/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 186.7937 - accuracy: 0.9990\n",
            "Epoch 368/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 184.4486 - accuracy: 0.9990\n",
            "Epoch 369/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 191.7332 - accuracy: 0.9989\n",
            "Epoch 370/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 189.6446 - accuracy: 0.9989\n",
            "Epoch 371/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 195.8085 - accuracy: 0.9990\n",
            "Epoch 372/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 185.1222 - accuracy: 0.9989\n",
            "Epoch 373/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 187.9003 - accuracy: 0.9989\n",
            "Epoch 374/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 193.5056 - accuracy: 0.9989\n",
            "Epoch 375/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 192.5625 - accuracy: 0.9990\n",
            "Epoch 376/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 189.4068 - accuracy: 0.9989\n",
            "Epoch 377/500\n",
            "582/582 [==============================] - 1s 3ms/step - loss: 190.0794 - accuracy: 0.9989\n",
            "Epoch 378/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 187.2990 - accuracy: 0.9990\n",
            "Epoch 379/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 192.2316 - accuracy: 0.9988\n",
            "Epoch 380/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 192.0116 - accuracy: 0.9989\n",
            "Epoch 381/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 193.5915 - accuracy: 0.9989\n",
            "Epoch 382/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 183.0669 - accuracy: 0.9989\n",
            "Epoch 383/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 197.0500 - accuracy: 0.9988\n",
            "Epoch 384/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 182.2115 - accuracy: 0.9990\n",
            "Epoch 385/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 191.0840 - accuracy: 0.9990\n",
            "Epoch 386/500\n",
            "582/582 [==============================] - 2s 3ms/step - loss: 188.5022 - accuracy: 0.9990\n",
            "Epoch 387/500\n",
            "582/582 [==============================] - 2s 3ms/step - loss: 189.0860 - accuracy: 0.9990\n",
            "Epoch 388/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 192.1858 - accuracy: 0.9990\n",
            "Epoch 389/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 186.8915 - accuracy: 0.9989\n",
            "Epoch 390/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 192.1996 - accuracy: 0.9989\n",
            "Epoch 391/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 183.7785 - accuracy: 0.9990\n",
            "Epoch 392/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 190.5999 - accuracy: 0.9989\n",
            "Epoch 393/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 189.6492 - accuracy: 0.9990\n",
            "Epoch 394/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 190.4262 - accuracy: 0.9989\n",
            "Epoch 395/500\n",
            "582/582 [==============================] - 1s 3ms/step - loss: 187.5592 - accuracy: 0.9990\n",
            "Epoch 396/500\n",
            "582/582 [==============================] - 2s 3ms/step - loss: 193.0334 - accuracy: 0.9990\n",
            "Epoch 397/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 189.4964 - accuracy: 0.9990\n",
            "Epoch 398/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 187.9193 - accuracy: 0.9990\n",
            "Epoch 399/500\n",
            "582/582 [==============================] - 2s 3ms/step - loss: 191.5494 - accuracy: 0.9989\n",
            "Epoch 400/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 193.3174 - accuracy: 0.9990\n",
            "Epoch 401/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 182.8706 - accuracy: 0.9989\n",
            "Epoch 402/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 191.5070 - accuracy: 0.9989\n",
            "Epoch 403/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 194.0347 - accuracy: 0.9990\n",
            "Epoch 404/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 187.7900 - accuracy: 0.9989\n",
            "Epoch 405/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 183.4327 - accuracy: 0.9990\n",
            "Epoch 406/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 183.8251 - accuracy: 0.9989\n",
            "Epoch 407/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 194.2505 - accuracy: 0.9989\n",
            "Epoch 408/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 189.7946 - accuracy: 0.9990\n",
            "Epoch 409/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 188.5704 - accuracy: 0.9989\n",
            "Epoch 410/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 185.6833 - accuracy: 0.9989\n",
            "Epoch 411/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 188.4053 - accuracy: 0.9990\n",
            "Epoch 412/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 188.0524 - accuracy: 0.9989\n",
            "Epoch 413/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 191.3749 - accuracy: 0.9990\n",
            "Epoch 414/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 184.7782 - accuracy: 0.9989\n",
            "Epoch 415/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 189.1891 - accuracy: 0.9989\n",
            "Epoch 416/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 187.1240 - accuracy: 0.9990\n",
            "Epoch 417/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 190.9092 - accuracy: 0.9989\n",
            "Epoch 418/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 190.8914 - accuracy: 0.9990\n",
            "Epoch 419/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 185.6449 - accuracy: 0.9990\n",
            "Epoch 420/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 186.7177 - accuracy: 0.9989\n",
            "Epoch 421/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 186.0387 - accuracy: 0.9989\n",
            "Epoch 422/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 188.2797 - accuracy: 0.9990\n",
            "Epoch 423/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 184.8728 - accuracy: 0.9990\n",
            "Epoch 424/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 190.3500 - accuracy: 0.9990\n",
            "Epoch 425/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 187.4395 - accuracy: 0.9990\n",
            "Epoch 426/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 184.1424 - accuracy: 0.9989\n",
            "Epoch 427/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 184.9154 - accuracy: 0.9990\n",
            "Epoch 428/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 187.2242 - accuracy: 0.9989\n",
            "Epoch 429/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 189.7607 - accuracy: 0.9989\n",
            "Epoch 430/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 181.3184 - accuracy: 0.9990\n",
            "Epoch 431/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 188.4310 - accuracy: 0.9990\n",
            "Epoch 432/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 185.2950 - accuracy: 0.9989\n",
            "Epoch 433/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 181.1934 - accuracy: 0.9990\n",
            "Epoch 434/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 184.2501 - accuracy: 0.9990\n",
            "Epoch 435/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 190.3260 - accuracy: 0.9990\n",
            "Epoch 436/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 177.9281 - accuracy: 0.9990\n",
            "Epoch 437/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 183.0395 - accuracy: 0.9990\n",
            "Epoch 438/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 179.3884 - accuracy: 0.9990\n",
            "Epoch 439/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 184.2823 - accuracy: 0.9988\n",
            "Epoch 440/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 176.2472 - accuracy: 0.9990\n",
            "Epoch 441/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 185.5513 - accuracy: 0.9989\n",
            "Epoch 442/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 174.5264 - accuracy: 0.9990\n",
            "Epoch 443/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 187.4831 - accuracy: 0.9989\n",
            "Epoch 444/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 175.1774 - accuracy: 0.9990\n",
            "Epoch 445/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 181.4762 - accuracy: 0.9990\n",
            "Epoch 446/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 183.0312 - accuracy: 0.9990\n",
            "Epoch 447/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 175.9787 - accuracy: 0.9989\n",
            "Epoch 448/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 177.7098 - accuracy: 0.9990\n",
            "Epoch 449/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 182.9816 - accuracy: 0.9989\n",
            "Epoch 450/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 182.5488 - accuracy: 0.9989\n",
            "Epoch 451/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 180.2871 - accuracy: 0.9989\n",
            "Epoch 452/500\n",
            "582/582 [==============================] - 1s 3ms/step - loss: 186.2872 - accuracy: 0.9989\n",
            "Epoch 453/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 177.4737 - accuracy: 0.9988\n",
            "Epoch 454/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 173.0516 - accuracy: 0.9990\n",
            "Epoch 455/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 183.2491 - accuracy: 0.9989\n",
            "Epoch 456/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 171.7896 - accuracy: 0.9989\n",
            "Epoch 457/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 178.9496 - accuracy: 0.9990\n",
            "Epoch 458/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 178.9393 - accuracy: 0.9989\n",
            "Epoch 459/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 184.0120 - accuracy: 0.9990\n",
            "Epoch 460/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 177.3878 - accuracy: 0.9990\n",
            "Epoch 461/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 172.9200 - accuracy: 0.9989\n",
            "Epoch 462/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 183.1010 - accuracy: 0.9990\n",
            "Epoch 463/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 180.6314 - accuracy: 0.9990\n",
            "Epoch 464/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 180.3854 - accuracy: 0.9989\n",
            "Epoch 465/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 180.6666 - accuracy: 0.9990\n",
            "Epoch 466/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 178.0042 - accuracy: 0.9989\n",
            "Epoch 467/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 179.7012 - accuracy: 0.9990\n",
            "Epoch 468/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 176.1222 - accuracy: 0.9989\n",
            "Epoch 469/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 176.9578 - accuracy: 0.9989\n",
            "Epoch 470/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 187.0934 - accuracy: 0.9990\n",
            "Epoch 471/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 172.8948 - accuracy: 0.9990\n",
            "Epoch 472/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 174.4427 - accuracy: 0.9990\n",
            "Epoch 473/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 176.4456 - accuracy: 0.9989\n",
            "Epoch 474/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 171.7101 - accuracy: 0.9989\n",
            "Epoch 475/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 181.1170 - accuracy: 0.9989\n",
            "Epoch 476/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 172.5914 - accuracy: 0.9989\n",
            "Epoch 477/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 179.7738 - accuracy: 0.9989\n",
            "Epoch 478/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 180.2277 - accuracy: 0.9990\n",
            "Epoch 479/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 178.2333 - accuracy: 0.9990\n",
            "Epoch 480/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 170.4790 - accuracy: 0.9990\n",
            "Epoch 481/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 179.9846 - accuracy: 0.9989\n",
            "Epoch 482/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 180.2185 - accuracy: 0.9989\n",
            "Epoch 483/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 180.1593 - accuracy: 0.9990\n",
            "Epoch 484/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 177.5917 - accuracy: 0.9989\n",
            "Epoch 485/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 183.7360 - accuracy: 0.9990\n",
            "Epoch 486/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 181.8709 - accuracy: 0.9990\n",
            "Epoch 487/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 175.3361 - accuracy: 0.9989\n",
            "Epoch 488/500\n",
            "582/582 [==============================] - 1s 3ms/step - loss: 182.4461 - accuracy: 0.9990\n",
            "Epoch 489/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 179.4049 - accuracy: 0.9989\n",
            "Epoch 490/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 175.5580 - accuracy: 0.9990\n",
            "Epoch 491/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 174.9637 - accuracy: 0.9990\n",
            "Epoch 492/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 180.0888 - accuracy: 0.9989\n",
            "Epoch 493/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 178.3501 - accuracy: 0.9989\n",
            "Epoch 494/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 178.1229 - accuracy: 0.9989\n",
            "Epoch 495/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 174.0645 - accuracy: 0.9989\n",
            "Epoch 496/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 176.1064 - accuracy: 0.9990\n",
            "Epoch 497/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 174.5518 - accuracy: 0.9989\n",
            "Epoch 498/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 177.0426 - accuracy: 0.9990\n",
            "Epoch 499/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 175.5743 - accuracy: 0.9990\n",
            "Epoch 500/500\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 164.9258 - accuracy: 0.9989\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7faad8fbf990>"
            ]
          },
          "metadata": {},
          "execution_count": 177
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EyNl7_bKBjTl",
        "outputId": "bbaf2a9a-6f45-4d50-b731-ee2daf5be548"
      },
      "source": [
        "loss,accuracy = model.evaluate(X_test, y_test)\n",
        "print(loss, accuracy)"
      ],
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "234/234 [==============================] - 0s 1ms/step - loss: 703.9299 - accuracy: 0.0206\n",
            "703.929931640625 0.020629605278372765\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WSMcDJFaCdbi"
      },
      "source": [
        "## Predict on eval dataset for further labeling."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v1O3J-fUESee"
      },
      "source": [
        "y_pred = model.predict(X_test)\n",
        "y_cls = (y_pred > 0.5).astype(\"int32\")"
      ],
      "execution_count": 178,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "35pPz6XlH9bB",
        "outputId": "fc654701-fe8f-443b-9ace-f32f61d9edae"
      },
      "source": [
        "(y_pred > 0.5).sum()"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "827"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B91pKTF8JNYN"
      },
      "source": [
        "def eval_model(y_test, y_cls):\n",
        "  y1 = y_test.reshape(-1)\n",
        "  y2 = y_cls.reshape(-1)\n",
        "  print(roc_auc_score(y1, y2))\n",
        "  print(classification_report(y1,y2))\n",
        "  print(confusion_matrix(y1,y2))\n"
      ],
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        },
        "id": "9_zSyw6yoU1S",
        "outputId": "9f60ed36-7875-46cc-eb1a-2c16d8a69f88"
      },
      "source": [
        "eval_model(y_train, y_cls)"
      ],
      "execution_count": 179,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-179-62491361021e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0meval_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_cls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-116-335ee418a666>\u001b[0m in \u001b[0;36meval_model\u001b[0;34m(y_test, y_cls)\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0my1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0my2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_cls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_ranking.py\u001b[0m in \u001b[0;36mroc_auc_score\u001b[0;34m(y_true, y_score, average, sample_weight, max_fpr, multi_class, labels)\u001b[0m\n\u001b[1;32m    388\u001b[0m                                              max_fpr=max_fpr),\n\u001b[1;32m    389\u001b[0m                                      \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 390\u001b[0;31m                                      sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    391\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# multilabel-indicator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m         return _average_binary_score(partial(_binary_roc_auc_score,\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_base.py\u001b[0m in \u001b[0;36m_average_binary_score\u001b[0;34m(binary_metric, y_true, y_score, average, sample_weight)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbinary_metric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_ranking.py\u001b[0m in \u001b[0;36m_binary_roc_auc_score\u001b[0;34m(y_true, y_score, sample_weight, max_fpr)\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m     fpr, tpr, _ = roc_curve(y_true, y_score,\n\u001b[0;32m--> 225\u001b[0;31m                             sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    226\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmax_fpr\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mmax_fpr\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mauc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_ranking.py\u001b[0m in \u001b[0;36mroc_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight, drop_intermediate)\u001b[0m\n\u001b[1;32m    769\u001b[0m     \"\"\"\n\u001b[1;32m    770\u001b[0m     fps, tps, thresholds = _binary_clf_curve(\n\u001b[0;32m--> 771\u001b[0;31m         y_true, y_score, pos_label=pos_label, sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    772\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    773\u001b[0m     \u001b[0;31m# Attempt to drop thresholds corresponding to points in between and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_ranking.py\u001b[0m in \u001b[0;36m_binary_clf_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight)\u001b[0m\n\u001b[1;32m    536\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{0} format is not supported\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 538\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    539\u001b[0m     \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m     \u001b[0my_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0;32m--> 212\u001b[0;31m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [37232, 7465]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BEGS90tDyMV6",
        "outputId": "b7424427-b1c4-4fec-d041-3936c368cee5"
      },
      "source": [
        "eval_model(y_test, y_cls)"
      ],
      "execution_count": 180,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.98      1.00      0.99      7311\n",
            "         1.0       0.00      0.00      0.00       154\n",
            "\n",
            "    accuracy                           0.98      7465\n",
            "   macro avg       0.49      0.50      0.49      7465\n",
            "weighted avg       0.96      0.98      0.97      7465\n",
            "\n",
            "[[7311    0]\n",
            " [ 154    0]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BYZigB-fymgd"
      },
      "source": [
        "def export_result(df_eval,y_pred):\n",
        "  '''\n",
        "  Attach the predicte result (probability) into original records.\n",
        "  Export to a csv file for further investication\n",
        "  '''\n",
        "  df_eval['predict'] = y_pred\n",
        "  df_eval['mid_value'] = abs(df_eval['predict'] - 0.5)\n",
        "  df_eval = df_eval.sort_values('mid_value')\n",
        "  value_limit = df_eval.iloc[200,-1]\n",
        "  df_record4label = df_eval[(df_eval['mid_value'] <= value_limit)|(df_eval['fraud'] == 1)]\n",
        "  path = '/content/drive/MyDrive/Colab Notebooks/finalproject/'\n",
        "  file_csv = path + 'for_label.csv'\n",
        "  df_record4label.to_csv(file_csv)\n",
        "  return True\n"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dI0Pw_Ur3xbd",
        "outputId": "75ccc644-ccd3-48ca-a126-7cfb9c8de1ef"
      },
      "source": [
        "record_to_label(df_eval,y_pred)"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    }
  ]
}