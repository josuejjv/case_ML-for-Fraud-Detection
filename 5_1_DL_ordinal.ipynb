{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "5_1_DL_ordinal.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPM4RCJIIoWEwtjjVdWsXqh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ryanhao1115/ML-for-Fraud-Detection/blob/main/5_1_DL_ordinal.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ndtW0FwNmcWr",
        "outputId": "12f55f55-2aab-4c1f-8793-911b70f2924d"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oINI7xYSmpo8"
      },
      "source": [
        "## Deep Learning model with Ordinal encoding data\n",
        "1. import new return label data.\n",
        "2. Under sampling data to address imbalance class issue.\n",
        "4. Train model\n",
        "5. Eval model\n",
        "6. Create Risk-heatmap"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Gc_G68myO1w"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.backend import clear_session\n",
        "from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix\n",
        "import tensorflow as tf\n",
        "import random\n"
      ],
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wr3fxm5Waw2H"
      },
      "source": [
        "def reset_seeds():\n",
        "    '''\n",
        "    reset random seeds for modeling\n",
        "    '''\n",
        "    np.random.seed(1)\n",
        "    random.seed(2)\n",
        "    if tf.__version__[0] == '2':\n",
        "        tf.random.set_seed(3)\n",
        "    else:\n",
        "        tf.set_random_seed(3)\n",
        "    print(\"RANDOM SEEDS RESET\")"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EB5yPnJdyRnG"
      },
      "source": [
        "## import dataset \n",
        "path = '/content/drive/MyDrive/Colab Notebooks/finalproject/'\n",
        "file = path + 'sales_clean.csv'\n",
        "df = pd.read_csv(file)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zM0xX0nKWIu0"
      },
      "source": [
        "df = df.drop(columns='Unnamed: 0')"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tXuAbPlSyWVW",
        "outputId": "e12cbefe-322b-41c4-f4cd-0661483ad5f7"
      },
      "source": [
        "df.nunique()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "distributor        639\n",
              "sales              209\n",
              "branch              28\n",
              "inv_type             3\n",
              "invoice_no       30721\n",
              "product_no        1094\n",
              "prod_cla             7\n",
              "qty                202\n",
              "total_amt        16112\n",
              "sale_price        8598\n",
              "ship_qty           202\n",
              "cust_type           20\n",
              "return               2\n",
              "discount_app         2\n",
              "list_price        6720\n",
              "inv_ship_days      133\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lCCJjJWqGLvU"
      },
      "source": [
        "## import return label data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cYVtnDc2HXFA"
      },
      "source": [
        "## import fraud data\n",
        "file = path + 'frauds.csv'\n",
        "df_fraud = pd.read_csv(file,header=None)\n",
        "df_fraud.columns = ['invoice_no']"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YntiE6PVIrPC"
      },
      "source": [
        "## import return new labeled data\n",
        "file = path + 'return.csv'\n",
        "df_fraud2 = pd.read_csv(file,header=None)\n",
        "df_fraud2.columns = ['invoice_no']"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CiNt30SZf6aD",
        "outputId": "9ad2d057-388f-4348-b8d4-89c9b1d3c26e"
      },
      "source": [
        "len(df_fraud2)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bo6Q08-CJyOv"
      },
      "source": [
        "def label_fraud(df, df_fraud, df_fraud2):\n",
        "  df['fraud'] = np.zeros(len(df))\n",
        "  frauds_l = df_fraud['invoice_no'].to_list()\n",
        "  frauds_l2 = df_fraud2['invoice_no'].to_list()\n",
        "  df.loc[df['invoice_no'].isin(frauds_l),'fraud'] = 1\n",
        "  df.loc[df['invoice_no'].isin(frauds_l2),'fraud'] = 2\n",
        "  return df"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y0iwhuZ_XIpE"
      },
      "source": [
        "df = label_fraud(df, df_fraud,df_fraud2)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S6y811N2NJZS",
        "outputId": "4a05289e-b7e3-407b-e8a4-3fccd22e35f2"
      },
      "source": [
        "df['fraud'].value_counts()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0    228014\n",
              "2.0       433\n",
              "1.0       154\n",
              "Name: fraud, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zYRaXHXsP07P"
      },
      "source": [
        "## Resampling to address the imbalance class\n",
        "Because fraud labels are given to invoice level, need to keep records of same invoice together. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d7PpSBXyT1iz"
      },
      "source": [
        "df_fraud = df[df['fraud'] == 1]\n",
        "df_non_fraud = df[df['fraud'] == 0]\n",
        "df_fraud2 = df[df['fraud'] == 2]"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eGH1pJ_JVnr7",
        "outputId": "1b2450fe-0cad-4483-b6b9-788a7d84a7b3"
      },
      "source": [
        "df_fraud2.info()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 433 entries, 19646 to 217825\n",
            "Data columns (total 17 columns):\n",
            " #   Column         Non-Null Count  Dtype  \n",
            "---  ------         --------------  -----  \n",
            " 0   distributor    433 non-null    object \n",
            " 1   sales          433 non-null    object \n",
            " 2   branch         433 non-null    int64  \n",
            " 3   inv_type       433 non-null    object \n",
            " 4   invoice_no     433 non-null    int64  \n",
            " 5   product_no     433 non-null    object \n",
            " 6   prod_cla       433 non-null    float64\n",
            " 7   qty            433 non-null    int64  \n",
            " 8   total_amt      433 non-null    float64\n",
            " 9   sale_price     433 non-null    float64\n",
            " 10  ship_qty       433 non-null    int64  \n",
            " 11  cust_type      433 non-null    object \n",
            " 12  return         433 non-null    int64  \n",
            " 13  discount_app   433 non-null    int64  \n",
            " 14  list_price     433 non-null    float64\n",
            " 15  inv_ship_days  433 non-null    int64  \n",
            " 16  fraud          433 non-null    float64\n",
            "dtypes: float64(5), int64(7), object(5)\n",
            "memory usage: 60.9+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M2L3ePEOXvyD"
      },
      "source": [
        "def sampling_inv(df_non_fraud):\n",
        "  '''\n",
        "  Random sampling from unlabled invoices.\n",
        "  '''\n",
        "  sample_inv = df_non_fraud['invoice_no'].unique()\n",
        "  print(len(sample_inv))\n",
        "  sample_inv1 = np.random.choice(sample_inv,size=1000,replace=False)\n",
        "  sample_inv = np.setdiff1d(sample_inv,sample_inv1)\n",
        "  print(len(sample_inv))\n",
        "  sample_inv2 = np.random.choice(sample_inv,size=5000,replace=False)\n",
        "  sample_inv = np.setdiff1d(sample_inv,sample_inv2)\n",
        "  print(len(sample_inv))\n",
        "  return sample_inv1, sample_inv2, sample_inv\n"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l_tDCpKgY1W-",
        "outputId": "529b2cf8-356d-4191-c11c-0c55793fcb67"
      },
      "source": [
        "sample_inv1, sample_inv2, sample_inv = sampling_inv(df_non_fraud)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "30686\n",
            "29686\n",
            "24686\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aFm7Iw2VepcP",
        "outputId": "f94d6781-10d3-4f97-83bd-a204ba8f3042"
      },
      "source": [
        "len(np.unique(sample_inv2))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5000"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Js8R7sDr7BM"
      },
      "source": [
        "## Build training dataset\n",
        "df_train = df_non_fraud[df_non_fraud['invoice_no'].isin(sample_inv2)]\n",
        "df_train = pd.concat([df_train,df_fraud2])\n",
        "df_train.loc[df_train['fraud'] == 2, 'fraud'] = 1 \n",
        "df_train = df_train.sort_index()"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O01agYImtUx9"
      },
      "source": [
        "## Build eval dataset\n",
        "df_test = df_non_fraud[df_non_fraud['invoice_no'].isin(sample_inv1)]\n",
        "df_test = pd.concat([df_test,df_fraud])\n",
        "df_test = df_test.sort_index()"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pzKw_DggxMS-",
        "outputId": "0d02b1b3-6fee-4424-a5ef-0ce6652c48a4"
      },
      "source": [
        "df_train.shape"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(37232, 17)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HqJlSiFlRwXl",
        "outputId": "e9ba5409-dd45-4a43-fe9a-ff6525e44e6b"
      },
      "source": [
        "df_test.shape"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7465, 17)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V_LOYj9ZZne0",
        "outputId": "59500217-5543-494e-c7f4-196dc9b7e621"
      },
      "source": [
        "df_train.info()"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 37232 entries, 108 to 228534\n",
            "Data columns (total 17 columns):\n",
            " #   Column         Non-Null Count  Dtype  \n",
            "---  ------         --------------  -----  \n",
            " 0   distributor    37232 non-null  object \n",
            " 1   sales          37232 non-null  object \n",
            " 2   branch         37232 non-null  int64  \n",
            " 3   inv_type       37232 non-null  object \n",
            " 4   invoice_no     37232 non-null  int64  \n",
            " 5   product_no     37232 non-null  object \n",
            " 6   prod_cla       37232 non-null  float64\n",
            " 7   qty            37232 non-null  int64  \n",
            " 8   total_amt      37232 non-null  float64\n",
            " 9   sale_price     37232 non-null  float64\n",
            " 10  ship_qty       37232 non-null  int64  \n",
            " 11  cust_type      37232 non-null  object \n",
            " 12  return         37232 non-null  int64  \n",
            " 13  discount_app   37232 non-null  int64  \n",
            " 14  list_price     37232 non-null  float64\n",
            " 15  inv_ship_days  37232 non-null  int64  \n",
            " 16  fraud          37232 non-null  float64\n",
            "dtypes: float64(5), int64(7), object(5)\n",
            "memory usage: 5.1+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l7OnGZt9GEAL"
      },
      "source": [
        "## Encoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T0O7sPin33OP"
      },
      "source": [
        "cols = df.columns.to_list()\n",
        "cols = ['distributor', 'sales', 'branch', 'inv_type', 'invoice_no', 'product_no', 'prod_cla', 'cust_type']"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "486mzoZj2LsQ"
      },
      "source": [
        "def field_encoding(df_train, df_eval):\n",
        "  '''\n",
        "  Ordinal encode categorical fields.\n",
        "  '''\n",
        "  cols = ['distributor', 'sales', 'branch', 'inv_type', 'invoice_no', 'product_no', 'prod_cla', 'cust_type']\n",
        "  df_train[cols] = df_train[cols].astype('str') \n",
        "  df_test[cols] = df_test[cols].astype('str') \n",
        "  df1 = pd.concat([df_train, df_test])\n",
        "  enc = LabelEncoder()\n",
        "  for f in cols:\n",
        "    enc.fit(df1[f])\n",
        "    df_train[f] = enc.transform(df_train[f])\n",
        "    df_test[f] = enc.transform(df_test[f])\n",
        "  return df_train, df_test"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qgVnIE3j7G0X"
      },
      "source": [
        "X_train = df_train.copy()\n",
        "X_test = df_test.copy()\n",
        "X_train, X_test = field_encoding(X_train, X_test)"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PdzuM0U2jb9V",
        "outputId": "77a74b01-e851-4496-c2ac-6c905b07e7ee"
      },
      "source": [
        "print(len(X_test),len(X_train))"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7465 37232\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A7gwzMqo8zkK",
        "outputId": "600249d0-31ff-4981-feae-8959d13f79a0"
      },
      "source": [
        "X_train.nunique()"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "distributor       518\n",
              "sales             187\n",
              "branch             28\n",
              "inv_type            3\n",
              "invoice_no       5024\n",
              "product_no        785\n",
              "prod_cla            7\n",
              "qty                89\n",
              "total_amt        5363\n",
              "sale_price       3725\n",
              "ship_qty           90\n",
              "cust_type          20\n",
              "return              2\n",
              "discount_app        2\n",
              "list_price       3012\n",
              "inv_ship_days      75\n",
              "fraud               2\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gDkexYmPxM8O"
      },
      "source": [
        "## Standardscale data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wxt4dsJo7tDa"
      },
      "source": [
        "scaler = StandardScaler()"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YeeK6JNC8Fqz"
      },
      "source": [
        "y_train = X_train['fraud'].values\n",
        "X_train = X_train.drop(columns=['fraud'])\n",
        "\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "y_train = y_train.reshape(len(y_train),1)"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "86joAZPl9YpL"
      },
      "source": [
        "y_test = X_test['fraud'].values\n",
        "X_test = X_test.drop(columns=['fraud'])\n",
        "\n",
        "X_test = scaler.transform(X_test)\n",
        "y_test = y_test.reshape(len(y_test),1)"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MNUBFns291Qv",
        "outputId": "21674f79-4e99-4b2e-ab55-1fc39c8682da"
      },
      "source": [
        "X_train[0]"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.31969424,  0.81761482, -1.18807636,  0.01829786, -1.70644042,\n",
              "        1.7724664 , -0.0709056 , -0.00639322,  1.28657546,  3.27756406,\n",
              "        0.0045258 , -0.77624262, -0.0163908 ,  0.01036562,  3.27549634,\n",
              "       -0.06245374])"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4o9UXO0--hgv",
        "outputId": "a17586c3-7590-4424-91e9-fc21f2605af4"
      },
      "source": [
        "y_test.shape"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7465, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gMv9MH5QVu6B",
        "outputId": "9b46608e-75f2-4ad9-d46c-fc21da3cad8f"
      },
      "source": [
        "y_train.sum()"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "433.0"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vnO2HnA4_RQU"
      },
      "source": [
        "## Build model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "09WCa-Qn_T0G"
      },
      "source": [
        "# define the  model\n",
        "def build_model():\n",
        "  model = Sequential()\n",
        "  model.add(Dense(32, input_dim=X_train.shape[1], activation='relu', kernel_initializer='he_normal'))\n",
        "  model.add(Dense(16,activation='relu'))\n",
        "  model.add(Dense(1, activation='sigmoid'))\n",
        "  # compile the keras model\n",
        "  # opt = tf.keras.optimizers.Adam(clipnorm=1, learning_rate=0.01)\n",
        "  model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "  return model"
      ],
      "execution_count": 192,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pBs2KuNeAErs",
        "outputId": "5da98c3a-810d-48b2-bad7-ec8163bb960e"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 64)                1088      \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 3,201\n",
            "Trainable params: 3,201\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cfEQ-OXDA3mV"
      },
      "source": [
        "## Training model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "413m67NPZY4F",
        "outputId": "c1c20f8e-8082-4807-ff40-45d45b1807b9"
      },
      "source": [
        "## clear previous model.  Make sure training from 0. \n",
        "del model\n",
        "clear_session()\n",
        "tf.compat.v1.reset_default_graph()\n",
        "reset_seeds()\n",
        "model = build_model()"
      ],
      "execution_count": 198,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RANDOM SEEDS RESET\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pp9q-HK4A6UX",
        "outputId": "6a69783a-e3d5-4c7e-b4a5-bb344ce6f587"
      },
      "source": [
        "model.fit(X_test, y_test, epochs=200,batch_size=64,class_weight={0:5, 1:30000})"
      ],
      "execution_count": 194,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "582/582 [==============================] - 2s 2ms/step - loss: 68.4741 - accuracy: 0.0469\n",
            "Epoch 2/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 24.8963 - accuracy: 0.0117\n",
            "Epoch 3/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 23.3393 - accuracy: 0.0118\n",
            "Epoch 4/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 22.1724 - accuracy: 0.0120\n",
            "Epoch 5/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 20.8699 - accuracy: 0.0121\n",
            "Epoch 6/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 19.3452 - accuracy: 0.0172\n",
            "Epoch 7/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 17.6756 - accuracy: 0.0425\n",
            "Epoch 8/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 16.0496 - accuracy: 0.1044\n",
            "Epoch 9/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 14.9536 - accuracy: 0.1946\n",
            "Epoch 10/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 13.8652 - accuracy: 0.2532\n",
            "Epoch 11/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 13.0510 - accuracy: 0.3198\n",
            "Epoch 12/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 11.5805 - accuracy: 0.3795\n",
            "Epoch 13/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 11.4285 - accuracy: 0.4284\n",
            "Epoch 14/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 10.0091 - accuracy: 0.4739\n",
            "Epoch 15/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 9.5480 - accuracy: 0.5130\n",
            "Epoch 16/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 8.6319 - accuracy: 0.5470\n",
            "Epoch 17/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 7.7879 - accuracy: 0.5940\n",
            "Epoch 18/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 8.3718 - accuracy: 0.5940\n",
            "Epoch 19/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 7.7478 - accuracy: 0.6277\n",
            "Epoch 20/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 6.5690 - accuracy: 0.6587\n",
            "Epoch 21/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 6.0873 - accuracy: 0.6871\n",
            "Epoch 22/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 6.6814 - accuracy: 0.6857\n",
            "Epoch 23/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 5.3623 - accuracy: 0.7226\n",
            "Epoch 24/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 5.2544 - accuracy: 0.7378\n",
            "Epoch 25/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 5.4754 - accuracy: 0.7427\n",
            "Epoch 26/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 4.8622 - accuracy: 0.7564\n",
            "Epoch 27/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 4.5987 - accuracy: 0.7731\n",
            "Epoch 28/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 4.4818 - accuracy: 0.7851\n",
            "Epoch 29/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 4.2775 - accuracy: 0.7941\n",
            "Epoch 30/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 3.9593 - accuracy: 0.8122\n",
            "Epoch 31/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 3.9335 - accuracy: 0.8102\n",
            "Epoch 32/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 3.9578 - accuracy: 0.8174\n",
            "Epoch 33/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 3.5129 - accuracy: 0.8309\n",
            "Epoch 34/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 3.5879 - accuracy: 0.8283\n",
            "Epoch 35/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 3.0737 - accuracy: 0.8480\n",
            "Epoch 36/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 3.4851 - accuracy: 0.8410\n",
            "Epoch 37/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 3.0612 - accuracy: 0.8520\n",
            "Epoch 38/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 2.9710 - accuracy: 0.8603\n",
            "Epoch 39/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 2.8604 - accuracy: 0.8677\n",
            "Epoch 40/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 2.5349 - accuracy: 0.8764\n",
            "Epoch 41/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 2.5919 - accuracy: 0.8766\n",
            "Epoch 42/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 2.7965 - accuracy: 0.8731\n",
            "Epoch 43/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 2.4085 - accuracy: 0.8857\n",
            "Epoch 44/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 6.1524 - accuracy: 0.8478\n",
            "Epoch 45/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 3.0812 - accuracy: 0.8675\n",
            "Epoch 46/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 2.4973 - accuracy: 0.8814\n",
            "Epoch 47/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 2.3421 - accuracy: 0.8886\n",
            "Epoch 48/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 2.2173 - accuracy: 0.8933\n",
            "Epoch 49/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 2.0187 - accuracy: 0.9016\n",
            "Epoch 50/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 2.0317 - accuracy: 0.9024\n",
            "Epoch 51/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 2.0925 - accuracy: 0.9013\n",
            "Epoch 52/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 2.0727 - accuracy: 0.9038\n",
            "Epoch 53/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 2.2150 - accuracy: 0.8982\n",
            "Epoch 54/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 1.8872 - accuracy: 0.9110\n",
            "Epoch 55/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 2.1960 - accuracy: 0.9034\n",
            "Epoch 56/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 1.9037 - accuracy: 0.9097\n",
            "Epoch 57/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 1.8510 - accuracy: 0.9144\n",
            "Epoch 58/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 1.7008 - accuracy: 0.9209\n",
            "Epoch 59/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 1.6945 - accuracy: 0.9232\n",
            "Epoch 60/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 1.8695 - accuracy: 0.9135\n",
            "Epoch 61/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 1.5014 - accuracy: 0.9297\n",
            "Epoch 62/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 1.5116 - accuracy: 0.9314\n",
            "Epoch 63/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 2.3132 - accuracy: 0.9102\n",
            "Epoch 64/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 1.4426 - accuracy: 0.9343\n",
            "Epoch 65/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 1.3267 - accuracy: 0.9387\n",
            "Epoch 66/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 1.2762 - accuracy: 0.9406\n",
            "Epoch 67/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 2.6369 - accuracy: 0.9150\n",
            "Epoch 68/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 4.6628 - accuracy: 0.8798\n",
            "Epoch 69/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 3.8278 - accuracy: 0.8945\n",
            "Epoch 70/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 2.5149 - accuracy: 0.8959\n",
            "Epoch 71/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 1.7845 - accuracy: 0.9229\n",
            "Epoch 72/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 1.5333 - accuracy: 0.9312\n",
            "Epoch 73/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 3.4942 - accuracy: 0.8994\n",
            "Epoch 74/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 3.1150 - accuracy: 0.9078\n",
            "Epoch 75/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 3.0670 - accuracy: 0.9114\n",
            "Epoch 76/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 2.2391 - accuracy: 0.9183\n",
            "Epoch 77/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 1.7248 - accuracy: 0.9322\n",
            "Epoch 78/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 1.4411 - accuracy: 0.9381\n",
            "Epoch 79/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 1.3417 - accuracy: 0.9410\n",
            "Epoch 80/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 1.2192 - accuracy: 0.9462\n",
            "Epoch 81/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 1.4988 - accuracy: 0.9409\n",
            "Epoch 82/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 1.6501 - accuracy: 0.9310\n",
            "Epoch 83/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 1.4402 - accuracy: 0.9359\n",
            "Epoch 84/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 1.2156 - accuracy: 0.9460\n",
            "Epoch 85/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 1.0839 - accuracy: 0.9524\n",
            "Epoch 86/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 1.1050 - accuracy: 0.9522\n",
            "Epoch 87/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 0.9957 - accuracy: 0.9553\n",
            "Epoch 88/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 3.8995 - accuracy: 0.8903\n",
            "Epoch 89/300\n",
            "582/582 [==============================] - 2s 3ms/step - loss: 2.8728 - accuracy: 0.9006\n",
            "Epoch 90/300\n",
            "582/582 [==============================] - 2s 3ms/step - loss: 2.0766 - accuracy: 0.9266\n",
            "Epoch 91/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 2.9043 - accuracy: 0.9142\n",
            "Epoch 92/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 1.4842 - accuracy: 0.9457\n",
            "Epoch 93/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 1.1263 - accuracy: 0.9529\n",
            "Epoch 94/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 0.9933 - accuracy: 0.9555\n",
            "Epoch 95/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 1.1898 - accuracy: 0.9506\n",
            "Epoch 96/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 0.8961 - accuracy: 0.9602\n",
            "Epoch 97/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 0.9912 - accuracy: 0.9575\n",
            "Epoch 98/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 0.8886 - accuracy: 0.9594\n",
            "Epoch 99/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 0.7898 - accuracy: 0.9637\n",
            "Epoch 100/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 0.8031 - accuracy: 0.9642\n",
            "Epoch 101/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 0.8531 - accuracy: 0.9638\n",
            "Epoch 102/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 6.1658 - accuracy: 0.8655\n",
            "Epoch 103/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 5.1425 - accuracy: 0.8768\n",
            "Epoch 104/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 2.5837 - accuracy: 0.9199\n",
            "Epoch 105/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 1.5238 - accuracy: 0.9494\n",
            "Epoch 106/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 1.3028 - accuracy: 0.9551\n",
            "Epoch 107/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 1.1781 - accuracy: 0.9562\n",
            "Epoch 108/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 0.9795 - accuracy: 0.9626\n",
            "Epoch 109/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 0.8747 - accuracy: 0.9648\n",
            "Epoch 110/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 0.8405 - accuracy: 0.9654\n",
            "Epoch 111/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 0.7832 - accuracy: 0.9679\n",
            "Epoch 112/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 1.0062 - accuracy: 0.9601\n",
            "Epoch 113/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 11.5173 - accuracy: 0.9229\n",
            "Epoch 114/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 2.4565 - accuracy: 0.9408\n",
            "Epoch 115/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 1.4342 - accuracy: 0.9565\n",
            "Epoch 116/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 1.0889 - accuracy: 0.9621\n",
            "Epoch 117/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 0.9348 - accuracy: 0.9662\n",
            "Epoch 118/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 1.3533 - accuracy: 0.9582\n",
            "Epoch 119/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 1.2029 - accuracy: 0.9611\n",
            "Epoch 120/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 1.2103 - accuracy: 0.9578\n",
            "Epoch 121/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 0.9794 - accuracy: 0.9637\n",
            "Epoch 122/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 1.3280 - accuracy: 0.9563\n",
            "Epoch 123/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 1.0552 - accuracy: 0.9603\n",
            "Epoch 124/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 0.8536 - accuracy: 0.9670\n",
            "Epoch 125/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 0.8093 - accuracy: 0.9675\n",
            "Epoch 126/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 0.7148 - accuracy: 0.9698\n",
            "Epoch 127/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 0.8113 - accuracy: 0.9673\n",
            "Epoch 128/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 0.6760 - accuracy: 0.9716\n",
            "Epoch 129/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 0.6641 - accuracy: 0.9728\n",
            "Epoch 130/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 0.7498 - accuracy: 0.9695\n",
            "Epoch 131/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 0.7284 - accuracy: 0.9690\n",
            "Epoch 132/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 0.5519 - accuracy: 0.9767\n",
            "Epoch 133/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 0.9511 - accuracy: 0.9643\n",
            "Epoch 134/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 1.1488 - accuracy: 0.9623\n",
            "Epoch 135/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 0.7134 - accuracy: 0.9757\n",
            "Epoch 136/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 3.6882 - accuracy: 0.9413\n",
            "Epoch 137/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 2.3956 - accuracy: 0.9467\n",
            "Epoch 138/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 1.5696 - accuracy: 0.9559\n",
            "Epoch 139/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 1.6042 - accuracy: 0.9659\n",
            "Epoch 140/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 1.5444 - accuracy: 0.9546\n",
            "Epoch 141/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 1.1029 - accuracy: 0.9677\n",
            "Epoch 142/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 0.9727 - accuracy: 0.9698\n",
            "Epoch 143/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 0.8904 - accuracy: 0.9718\n",
            "Epoch 144/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 0.8956 - accuracy: 0.9719\n",
            "Epoch 145/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 0.8271 - accuracy: 0.9726\n",
            "Epoch 146/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 0.6263 - accuracy: 0.9764\n",
            "Epoch 147/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 0.7493 - accuracy: 0.9706\n",
            "Epoch 148/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 0.5490 - accuracy: 0.9773\n",
            "Epoch 149/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 1.0035 - accuracy: 0.9705\n",
            "Epoch 150/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 0.9200 - accuracy: 0.9734\n",
            "Epoch 151/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 0.5918 - accuracy: 0.9795\n",
            "Epoch 152/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 0.5399 - accuracy: 0.9792\n",
            "Epoch 153/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 0.6258 - accuracy: 0.9775\n",
            "Epoch 154/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 0.8409 - accuracy: 0.9720\n",
            "Epoch 155/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 0.6677 - accuracy: 0.9764\n",
            "Epoch 156/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 0.6261 - accuracy: 0.9761\n",
            "Epoch 157/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 0.4946 - accuracy: 0.9793\n",
            "Epoch 158/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 3.8237 - accuracy: 0.9464\n",
            "Epoch 159/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 1.6809 - accuracy: 0.9601\n",
            "Epoch 160/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 1.1428 - accuracy: 0.9621\n",
            "Epoch 161/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 0.7369 - accuracy: 0.9736\n",
            "Epoch 162/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 0.6136 - accuracy: 0.9774\n",
            "Epoch 163/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 0.5122 - accuracy: 0.9804\n",
            "Epoch 164/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 0.4608 - accuracy: 0.9813\n",
            "Epoch 165/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 0.6149 - accuracy: 0.9771\n",
            "Epoch 166/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 0.6593 - accuracy: 0.9766\n",
            "Epoch 167/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 0.4965 - accuracy: 0.9808\n",
            "Epoch 168/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 0.4239 - accuracy: 0.9836\n",
            "Epoch 169/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 0.8837 - accuracy: 0.9711\n",
            "Epoch 170/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 2.1769 - accuracy: 0.9759\n",
            "Epoch 171/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 4.5841 - accuracy: 0.9208\n",
            "Epoch 172/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 3.2202 - accuracy: 0.9076\n",
            "Epoch 173/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 1.3834 - accuracy: 0.9596\n",
            "Epoch 174/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 1.0669 - accuracy: 0.9656\n",
            "Epoch 175/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 0.7764 - accuracy: 0.9724\n",
            "Epoch 176/300\n",
            "582/582 [==============================] - 1s 3ms/step - loss: 0.6420 - accuracy: 0.9752\n",
            "Epoch 177/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 0.5957 - accuracy: 0.9759\n",
            "Epoch 178/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 0.5893 - accuracy: 0.9769\n",
            "Epoch 179/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 0.5047 - accuracy: 0.9792\n",
            "Epoch 180/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 0.6990 - accuracy: 0.9781\n",
            "Epoch 181/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 0.9998 - accuracy: 0.9679\n",
            "Epoch 182/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 0.7506 - accuracy: 0.9752\n",
            "Epoch 183/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 0.6949 - accuracy: 0.9759\n",
            "Epoch 184/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 0.6087 - accuracy: 0.9778\n",
            "Epoch 185/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 0.6004 - accuracy: 0.9781\n",
            "Epoch 186/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 0.4561 - accuracy: 0.9811\n",
            "Epoch 187/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 5.3624 - accuracy: 0.9650\n",
            "Epoch 188/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 5.2512 - accuracy: 0.8914\n",
            "Epoch 189/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 2.7733 - accuracy: 0.9512\n",
            "Epoch 190/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 2.4870 - accuracy: 0.9586\n",
            "Epoch 191/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 2.0276 - accuracy: 0.9533\n",
            "Epoch 192/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 1.2818 - accuracy: 0.9660\n",
            "Epoch 193/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 0.8930 - accuracy: 0.9736\n",
            "Epoch 194/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 0.6570 - accuracy: 0.9782\n",
            "Epoch 195/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 0.5306 - accuracy: 0.9812\n",
            "Epoch 196/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 0.4957 - accuracy: 0.9822\n",
            "Epoch 197/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 0.6128 - accuracy: 0.9795\n",
            "Epoch 198/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 0.7163 - accuracy: 0.9787\n",
            "Epoch 199/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 0.5055 - accuracy: 0.9819\n",
            "Epoch 200/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 0.5759 - accuracy: 0.9790\n",
            "Epoch 201/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 0.5679 - accuracy: 0.9814\n",
            "Epoch 202/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 0.7519 - accuracy: 0.9754\n",
            "Epoch 203/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 0.4278 - accuracy: 0.9834\n",
            "Epoch 204/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 0.8332 - accuracy: 0.9770\n",
            "Epoch 205/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 0.5638 - accuracy: 0.9820\n",
            "Epoch 206/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 0.4131 - accuracy: 0.9841\n",
            "Epoch 207/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 0.4772 - accuracy: 0.9820\n",
            "Epoch 208/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 0.3976 - accuracy: 0.9846\n",
            "Epoch 209/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 1.8186 - accuracy: 0.9702\n",
            "Epoch 210/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 0.9829 - accuracy: 0.9807\n",
            "Epoch 211/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 0.6839 - accuracy: 0.9828\n",
            "Epoch 212/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 0.4219 - accuracy: 0.9869\n",
            "Epoch 213/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 0.3561 - accuracy: 0.9872\n",
            "Epoch 214/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 0.3916 - accuracy: 0.9850\n",
            "Epoch 215/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 0.3477 - accuracy: 0.9869\n",
            "Epoch 216/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 1.2399 - accuracy: 0.9671\n",
            "Epoch 217/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 0.5923 - accuracy: 0.9786\n",
            "Epoch 218/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 2.7865 - accuracy: 0.9511\n",
            "Epoch 219/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 1.5134 - accuracy: 0.9696\n",
            "Epoch 220/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 1.0110 - accuracy: 0.9788\n",
            "Epoch 221/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 0.7437 - accuracy: 0.9826\n",
            "Epoch 222/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 0.5595 - accuracy: 0.9859\n",
            "Epoch 223/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 0.4515 - accuracy: 0.9874\n",
            "Epoch 224/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 0.3945 - accuracy: 0.9881\n",
            "Epoch 225/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 0.3608 - accuracy: 0.9880\n",
            "Epoch 226/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 0.3682 - accuracy: 0.9874\n",
            "Epoch 227/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 0.3378 - accuracy: 0.9887\n",
            "Epoch 228/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 1.4957 - accuracy: 0.9659\n",
            "Epoch 229/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 0.9131 - accuracy: 0.9659\n",
            "Epoch 230/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 0.4468 - accuracy: 0.9811\n",
            "Epoch 231/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 0.3606 - accuracy: 0.9859\n",
            "Epoch 232/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 0.6943 - accuracy: 0.9831\n",
            "Epoch 233/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 0.5555 - accuracy: 0.9832\n",
            "Epoch 234/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 0.3274 - accuracy: 0.9882\n",
            "Epoch 235/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 0.2698 - accuracy: 0.9902\n",
            "Epoch 236/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 0.2604 - accuracy: 0.9896\n",
            "Epoch 237/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 0.3574 - accuracy: 0.9874\n",
            "Epoch 238/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 0.6092 - accuracy: 0.9797\n",
            "Epoch 239/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 11.5964 - accuracy: 0.9608\n",
            "Epoch 240/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 5.7235 - accuracy: 0.8801\n",
            "Epoch 241/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 2.9605 - accuracy: 0.9435\n",
            "Epoch 242/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 2.2315 - accuracy: 0.9591\n",
            "Epoch 243/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 1.7469 - accuracy: 0.9691\n",
            "Epoch 244/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 1.3873 - accuracy: 0.9744\n",
            "Epoch 245/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 1.0964 - accuracy: 0.9779\n",
            "Epoch 246/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 0.8806 - accuracy: 0.9806\n",
            "Epoch 247/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 0.7198 - accuracy: 0.9832\n",
            "Epoch 248/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 0.5999 - accuracy: 0.9843\n",
            "Epoch 249/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 0.4654 - accuracy: 0.9862\n",
            "Epoch 250/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 0.3760 - accuracy: 0.9881\n",
            "Epoch 251/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 0.3301 - accuracy: 0.9887\n",
            "Epoch 252/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 0.2833 - accuracy: 0.9893\n",
            "Epoch 253/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 0.3174 - accuracy: 0.9881\n",
            "Epoch 254/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 0.2568 - accuracy: 0.9896\n",
            "Epoch 255/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 0.2621 - accuracy: 0.9900\n",
            "Epoch 256/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 0.2270 - accuracy: 0.9904\n",
            "Epoch 257/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 0.6627 - accuracy: 0.9801\n",
            "Epoch 258/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 3.5109 - accuracy: 0.9605\n",
            "Epoch 259/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 1.7026 - accuracy: 0.9550\n",
            "Epoch 260/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 3.7420 - accuracy: 0.9481\n",
            "Epoch 261/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 6.4373 - accuracy: 0.8918\n",
            "Epoch 262/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 3.0746 - accuracy: 0.9292\n",
            "Epoch 263/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 1.5862 - accuracy: 0.9640\n",
            "Epoch 264/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 1.1669 - accuracy: 0.9722\n",
            "Epoch 265/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 0.9409 - accuracy: 0.9768\n",
            "Epoch 266/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 0.7412 - accuracy: 0.9803\n",
            "Epoch 267/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 0.6399 - accuracy: 0.9815\n",
            "Epoch 268/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 0.5112 - accuracy: 0.9836\n",
            "Epoch 269/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 0.4179 - accuracy: 0.9865\n",
            "Epoch 270/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 0.4829 - accuracy: 0.9846\n",
            "Epoch 271/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 0.4421 - accuracy: 0.9849\n",
            "Epoch 272/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 0.9007 - accuracy: 0.9722\n",
            "Epoch 273/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 1.9503 - accuracy: 0.9627\n",
            "Epoch 274/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 1.1486 - accuracy: 0.9811\n",
            "Epoch 275/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 0.9149 - accuracy: 0.9804\n",
            "Epoch 276/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 0.6748 - accuracy: 0.9844\n",
            "Epoch 277/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 0.4067 - accuracy: 0.9882\n",
            "Epoch 278/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 0.3272 - accuracy: 0.9889\n",
            "Epoch 279/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 0.3309 - accuracy: 0.9888\n",
            "Epoch 280/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 0.5335 - accuracy: 0.9844\n",
            "Epoch 281/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 0.4475 - accuracy: 0.9845\n",
            "Epoch 282/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 1.8212 - accuracy: 0.9763\n",
            "Epoch 283/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 2.6648 - accuracy: 0.9517\n",
            "Epoch 284/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 1.6456 - accuracy: 0.9747\n",
            "Epoch 285/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 1.1645 - accuracy: 0.9823\n",
            "Epoch 286/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 2.8655 - accuracy: 0.9663\n",
            "Epoch 287/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 1.6406 - accuracy: 0.9694\n",
            "Epoch 288/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 1.1831 - accuracy: 0.9778\n",
            "Epoch 289/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 0.9564 - accuracy: 0.9794\n",
            "Epoch 290/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 0.7518 - accuracy: 0.9818\n",
            "Epoch 291/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 0.6296 - accuracy: 0.9826\n",
            "Epoch 292/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 0.4906 - accuracy: 0.9842\n",
            "Epoch 293/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 0.3592 - accuracy: 0.9876\n",
            "Epoch 294/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 0.5994 - accuracy: 0.9801\n",
            "Epoch 295/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 0.3927 - accuracy: 0.9870\n",
            "Epoch 296/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 0.3463 - accuracy: 0.9868\n",
            "Epoch 297/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 0.3027 - accuracy: 0.9887\n",
            "Epoch 298/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 0.3041 - accuracy: 0.9887\n",
            "Epoch 299/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 0.2857 - accuracy: 0.9896\n",
            "Epoch 300/300\n",
            "582/582 [==============================] - 1s 2ms/step - loss: 0.3758 - accuracy: 0.9862\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7faad903eb90>"
            ]
          },
          "metadata": {},
          "execution_count": 194
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EyNl7_bKBjTl",
        "outputId": "63d8acbe-4669-48cb-8ac7-50de425d64f8"
      },
      "source": [
        "loss,accuracy = model.evaluate(X_test, y_test)\n",
        "print(loss, accuracy)"
      ],
      "execution_count": 195,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "234/234 [==============================] - 0s 1ms/step - loss: 8.6929 - accuracy: 0.9794\n",
            "8.692902565002441 0.9793704152107239\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WSMcDJFaCdbi"
      },
      "source": [
        "## Predict on eval dataset for further labeling."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v1O3J-fUESee"
      },
      "source": [
        "y_pred = model.predict(X_test)\n",
        "y_cls = (y_pred > 0.5).astype(\"int32\")"
      ],
      "execution_count": 196,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "35pPz6XlH9bB",
        "outputId": "fc654701-fe8f-443b-9ace-f32f61d9edae"
      },
      "source": [
        "(y_pred > 0.5).sum()"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "827"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B91pKTF8JNYN"
      },
      "source": [
        "def eval_model(y_test, y_cls):\n",
        "  y1 = y_test.reshape(-1)\n",
        "  y2 = y_cls.reshape(-1)\n",
        "  print(roc_auc_score(y1, y2))\n",
        "  print(classification_report(y1,y2))\n",
        "  print(confusion_matrix(y1,y2))\n"
      ],
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        },
        "id": "9_zSyw6yoU1S",
        "outputId": "9f60ed36-7875-46cc-eb1a-2c16d8a69f88"
      },
      "source": [
        "eval_model(y_train, y_cls)"
      ],
      "execution_count": 179,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-179-62491361021e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0meval_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_cls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-116-335ee418a666>\u001b[0m in \u001b[0;36meval_model\u001b[0;34m(y_test, y_cls)\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0my1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0my2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_cls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_ranking.py\u001b[0m in \u001b[0;36mroc_auc_score\u001b[0;34m(y_true, y_score, average, sample_weight, max_fpr, multi_class, labels)\u001b[0m\n\u001b[1;32m    388\u001b[0m                                              max_fpr=max_fpr),\n\u001b[1;32m    389\u001b[0m                                      \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 390\u001b[0;31m                                      sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    391\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# multilabel-indicator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m         return _average_binary_score(partial(_binary_roc_auc_score,\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_base.py\u001b[0m in \u001b[0;36m_average_binary_score\u001b[0;34m(binary_metric, y_true, y_score, average, sample_weight)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbinary_metric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_ranking.py\u001b[0m in \u001b[0;36m_binary_roc_auc_score\u001b[0;34m(y_true, y_score, sample_weight, max_fpr)\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m     fpr, tpr, _ = roc_curve(y_true, y_score,\n\u001b[0;32m--> 225\u001b[0;31m                             sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    226\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmax_fpr\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mmax_fpr\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mauc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_ranking.py\u001b[0m in \u001b[0;36mroc_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight, drop_intermediate)\u001b[0m\n\u001b[1;32m    769\u001b[0m     \"\"\"\n\u001b[1;32m    770\u001b[0m     fps, tps, thresholds = _binary_clf_curve(\n\u001b[0;32m--> 771\u001b[0;31m         y_true, y_score, pos_label=pos_label, sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    772\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    773\u001b[0m     \u001b[0;31m# Attempt to drop thresholds corresponding to points in between and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_ranking.py\u001b[0m in \u001b[0;36m_binary_clf_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight)\u001b[0m\n\u001b[1;32m    536\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{0} format is not supported\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 538\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    539\u001b[0m     \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m     \u001b[0my_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0;32m--> 212\u001b[0;31m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [37232, 7465]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BEGS90tDyMV6",
        "outputId": "1155b3bc-7010-4c85-d045-2a3591598959"
      },
      "source": [
        "eval_model(y_test, y_cls)"
      ],
      "execution_count": 197,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.98      1.00      0.99      7311\n",
            "         1.0       0.00      0.00      0.00       154\n",
            "\n",
            "    accuracy                           0.98      7465\n",
            "   macro avg       0.49      0.50      0.49      7465\n",
            "weighted avg       0.96      0.98      0.97      7465\n",
            "\n",
            "[[7311    0]\n",
            " [ 154    0]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BYZigB-fymgd"
      },
      "source": [
        "def export_result(df_eval,y_pred):\n",
        "  '''\n",
        "  Attach the predicte result (probability) into original records.\n",
        "  Export to a csv file for further investication\n",
        "  '''\n",
        "  df_eval['predict'] = y_pred\n",
        "  df_eval['mid_value'] = abs(df_eval['predict'] - 0.5)\n",
        "  df_eval = df_eval.sort_values('mid_value')\n",
        "  value_limit = df_eval.iloc[200,-1]\n",
        "  df_record4label = df_eval[(df_eval['mid_value'] <= value_limit)|(df_eval['fraud'] == 1)]\n",
        "  path = '/content/drive/MyDrive/Colab Notebooks/finalproject/'\n",
        "  file_csv = path + 'for_label.csv'\n",
        "  df_record4label.to_csv(file_csv)\n",
        "  return True\n"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dI0Pw_Ur3xbd",
        "outputId": "75ccc644-ccd3-48ca-a126-7cfb9c8de1ef"
      },
      "source": [
        "record_to_label(df_eval,y_pred)"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    }
  ]
}